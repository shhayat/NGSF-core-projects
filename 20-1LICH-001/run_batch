############################
#STEP1 : CONCATENATE PREPS
############################
SCRIPT_DIR=/globalhome/hxo752/HPC/ngsf_git_repos/NGSF-core-projects/20-1LICH-001
myarr=()
while read line
do 
   myarr+=("$line")
done < ${SCRIPT_DIR}/sample_IDs.txt

for i in {0..11}
do
  set ${myarr[i]}
      SAMPLE1=$2
      SAMPLE2=$3
   
   #$1 is CLONE_ID and $4 is conditions for sample
    sbatch ${SCRIPT_DIR}/00_concatenate_preps.sh $1 ${SAMPLE1} ${SAMPLE2} $4
   sleep 0.5
 done

####################
#STEP3 : ALIGNMENT
####################
DATA_DIR=/datastore/NGSF001/projects/2020/20-1LICH-001/concatenated_fastq

for i in $DATA_DIR/*R1*.fastq.gz
do
      path="${i%_R1*}";
      sample_name=${path##*/};

      fq1=${DATA_DIR}/${sample_name}_R1.fastq.gz;
      fq2=${DATA_DIR}/${sample_name}_R2.fastq.gz;

      sbatch ${SCRIPT_DIR}/02_bowtie_alignment.sh "${sample_name}" "${fq1}" "${fq2}"
  sleep 0.5
done


##########################################
#STEP4 : MARKDUPLICATES AND ADD READ GROUP
##########################################
SCRIPT_DIR=/globalhome/hxo752/HPC/ngsf_git_repos/NGSF-core-projects/20-1LICH-001/
DATA_DIR=/globalhome/hxo752/HPC/ngsf_git_repos/NGSF-core-projects/20-1LICH-001/analysis/concatenated_fastq

for i in $DATA_DIR/*R1*.fastq.gz
do
      path="${i%_R1*}";
      sample_name=${path##*/};

  sbatch ${SCRIPT_DIR}/03_markduplicates_and_add_Read_group.sh ${sample_name} "${DATA_DIR}/${sample_name}/${sample_name}.aligned.bam"
  sleep 0.5
done

#######################
#STEP5: RECALIBRATION
#######################
DATA_DIR=/globalhome/hxo752/HPC/ngsf_git_repos/NGSF-core-projects/20-1LICH-001/analysis/concatenated_fastq

for i in $DATA_DIR/*R1*.fastq.gz
do
      path="${i%_R1*}";
      sample_name=${path##*/};

    sbatch ${SCRIPT_DIR}/04_Bases_Quality_recalibration.sh ${sample_name} "${DATA}/${sample_name}/${sample_name}_mdup_rg.bam"
  sleep 0.2
done


#####################
#STEP3 : MUTECT2 CALL
#####################
SCRIPT_DIR=/globalhome/hxo752/HPC/ngsf_git_repos/NGSF-core-projects/20-1LICH-001
 
for i in $DATA_DIR/*R1*.fastq.gz
do
      path="${i%_R1*}";
      sample_name=${path##*/};

   sbatch ${SCRIPT_DIR}/05_mutect2_calling.sh ${sample_name}
   sleep 0.5
done


##########################
#STEP4 : SELECT VARIANTS
##########################
DATA=/globalhome/hxo752/HPC/ngsf_git_repos/NGSF-core-projects/20-1LICH-001/analysis/alignment
for i in $DATA_DIR/*R1*.fastq.gz
do
      path="${i%_R1*}";
      sample_name=${path##*/};

  sbatch ${SCRIPT_DIR}/06_select_variants.sh "${sample_name}"
  sleep  0.5

done

###############################################################
 MERGE UNINDUCED INDUCED SAMPLES PER PROTEIN
###############################################################
SCRIPT_DIR=/globalhome/hxo752/HPC/ngsf_git_repos/NGSF-core-projects/20-1LICH-001
myarr=()
while read line
do 
   myarr+=("$line")
done < ${SCRIPT_DIR}/sample_IDs.txt

for i in 2 6 10
do
  set ${myarr[i]}
      SAMPLE1=$2
   
   set ${myarr[i+1]}
      SAMPLE2=$2
   
   #$1 is CLONE_ID and $3 is conditions for sample
    sbatch ${SCRIPT_DIR}/04_concat_induced_uninduced.sh $1 ${SAMPLE1} ${SAMPLE2} $3
   sleep 0.5
 done

SCRIPT_DIR=/globalhome/hxo752/HPC/ngsf_git_repos/NGSF-core-projects/20-1LICH-001
myarr=()
while read line
do 
   myarr+=("$line")
done < ${SCRIPT_DIR}/sample_IDs.txt

for i in 0 4 8
do
  set ${myarr[i]}
      SAMPLE1=$2
   
   set ${myarr[i+1]}
      SAMPLE2=$2
   
   #$1 is CLONE_ID and $3 is conditions for sample
    sbatch ${SCRIPT_DIR}/04_concat_induced_uninduced.sh $1 ${SAMPLE1} ${SAMPLE2} $3
   sleep 0.5
 done


##########################
#STEP4 : SELECT VARIANTS
##########################
SCRIPT_DIR=/globalhome/hxo752/HPC/ngsf_git_repos/NGSF-core-projects/20-1LICH-001
myarr=()
while read line
do 
   myarr+=("$line")
done < ${SCRIPT_DIR}/sample_IDs.txt

for i in 0 4 8 2 6 10
do
   set ${myarr[i]}
   #1 is clone id and $3 is sample info
   sbatch ${SCRIPT_DIR}/05_select_variants.sh $1 $3
   sleep 0.5
 done

#########################################################################
#REMOVE SHARED VARIANTS BETWEEN INDUCED AND UNINDUCED PER PROTEINS
#########################################################################
SCRIPT_DIR=/globalhome/hxo752/HPC/ngsf_git_repos/NGSF-core-projects/20-1LICH-001/
myarr=()
while read line
do 
   myarr+=("$line")
done < ${SCRIPT_DIR}/sample_IDs.txt

for i in 0 1 4 5 8 9 
do
   set ${myarr[i]}
   CLONE_ID=$1 
   INDUCED_SAMPLE=$2
   
   sbatch ${SCRIPT_DIR}/05_remove_shared_variants.sh ${CLONE_ID} ${INDUCED_SAMPLE}
   sleep 0.5
 done





##########################
#CREATE PANEL OF NORMALS
##########################
#SCRIPT_DIR=/globalhome/hxo752/HPC/ngsf_git_repos/NGSF-core-projects/20-1LICH-001/
#myarr=()
#while read line
#do 
#   myarr+=("$line")
#done < ${SCRIPT_DIR}/sample_IDs.txt

#for i in 2 6 10
#do
#  set ${myarr[i]}
#  UNINDUCED_SAMPLE1=$2
   
#  set ${myarr[i+1]}
#  UNINDUCED_SAMPLE2=$2
   
   #$1 is CLONE_ID
 #   sbatch ${SCRIPT_DIR}/PON.sh $1 ${UNINDUCED_SAMPLE1} ${UNINDUCED_SAMPLE2}
 #  sleep 0.5
 #done


###########################################
#STEP3 : MERGE UNINDUCED SAMPLES PER PROTEIN
###########################################
#SCRIPT_DIR=/globalhome/hxo752/HPC/ngsf_git_repos/NGSF-core-projects/20-1LICH-001/
#myarr=()
#while read line
#do 
#   myarr+=("$line")
#done < ${SCRIPT_DIR}/sample_IDs.txt

#for i in 2 6 10
#do
#  set ${myarr[i]}
#   UNINDUCED_SAMPLE1=$2
   
#   set ${myarr[i+1]}
#   UNINDUCED_SAMPLE2=$2
   
   #$1 is CLONE_ID
#    sbatch ${SCRIPT_DIR}/03_concat_uninduced.sh $1 ${UNINDUCED_SAMPLE1} ${UNINDUCED_SAMPLE2}
#   sleep 0.5
# done


